# CS231n

I have been following the course CS231n: Convolutional Neural Networks for Visual Recognition offered by Stanford. This repository maintains the solutions to CS23N assignments.

Course Lectures: [Youtube](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk)\
Course Site: [CS231n](http://cs231n.stanford.edu/)\
A brief description of the assignments:

**Assignment 1**
1. [KNN](https://github.com/MananSuri27/CS231n/blob/main/assignment1/knn.ipynb)
- In this assignment, I implemented the K-Nearest Neighbour Algorithm from scratch using vectorised code, applying it on the CIFAR-10 dataset. This was also helpful in understanding basic Image Classification pipeline, cross-validation
2. [SVM](https://github.com/MananSuri27/CS231n/blob/main/assignment1/svm.ipynb)
- This assignment required me to implement a Multiclass Support Vector Machine (SVM) classifier. It also required me to write from scratch a code to implement SGD (Stochastic Gradient Descent) to optimise the loss function, helped me understand how to claculate the analytical gradient for vector equations.
3. [Softmax](https://github.com/MananSuri27/CS231n/blob/main/assignment1/softmax.ipynb)
- Here, I was required to implement a softmax classifier. Like the SVM assignment, this also required using analytical gradients and calculation of loss functions- something which helped clearsome fundamentals.
4. [Two Layer Neural Network](https://github.com/MananSuri27/CS231n/blob/main/assignment1/two_layer_net.ipynb)
- Built a two layer neural network from scratch by using modularised functions and classes.
- Implemented different layers like: affine, relu, vectorised loss functions for softmax and svm losses.
- Optimised using vanilla SGD.
- Effectively used computational graphs to understand gradient flow; implemented forward and backward passes.
- Tuning of hyperparameters using grid search.
